# AGI Core Concepts V1.0

This document lists core concepts related to Artificial General Intelligence (AGI) that will be used for categorizing research and guiding development. This initial list is extracted from provided research and project documentation.

## Foundational Capabilities
-   Learning (e.g., Machine Learning, Meta-Learning, RSI, Continual Learning)
-   Reasoning (e.g., Logical, Causal, Abstract, Common Sense, CoT, Planning)
-   Problem-Solving
-   Common Sense Knowledge
-   Creativity & Novelty
-   Perception (Multimodal)
-   Language Understanding & Generation (NLU, NLG)
-   Action & Embodiment

## Architectural Principles
-   Modularity
-   Integration
-   Adaptability
-   System Stability
-   World Models / Self-Models
-   Agent Architectures (e.g., LLM-based, Cognitive Architectures, Neuro-Symbolic)
-   Memory Systems (e.g., Hippocampal-Inspired, Dual Memory)

## Operational Aspects
-   Recursive Self-Improvement (RSI)
-   Automated Planning
-   Formal Verification & Reliability
-   Automated Testing
-   Runtime Monitoring & Anomaly Detection
-   Introspection & Metacognition
-   Self-Awareness / Goal-Awareness / Situational-Awareness
-   Tool Integration
-   Prompt Engineering (Various styles, e.g., CoT, Working Backwards, Fake CoT)
-   Information Intake Processing

## Data Considerations
-   Multimodal Data
-   Unstructured Data
-   Real-World Interaction / Embodied Data
-   Data Acquisition
-   Data Processing
-   Data Representation (e.g., Symbol Grounding, Knowledge Graphs)
-   Data Bias & Fairness
-   Data Privacy

## Evaluation
-   AGI Evaluation Metrics & Benchmarks (e.g., Turing Test, ARC-AGI, AGITB)
-   Generality (Breadth)
-   Performance (Depth)
-   Living Benchmarks

## Safety, Ethics, and Governance
-   Existential Risk (X-Risk)
-   Control Problem
-   Alignment Problem (Goal Misalignment)
-   Misuse Risks
-   Unforeseen Consequences / Accidents
-   Intelligence Explosion / Takeoff
-   Instrumental Convergence
-   Paperclip Maximizer / Squiggle Maximizer
-   Superintelligence (ASI)
-   Risk Mitigation / AI Safety
-   Technical Alignment Research
-   Control Methods (Containment, Capability Control, Tripwires, Kill Switches)
-   Safety Standards & Evaluation
-   Governance & Regulation (International Treaties, Compute Governance, Tiered Standards, Liability)
-   Ethical Guidelines & Principles
-   Moral Status / Rights / Personhood
-   Agency / Responsibility / Accountability
-   Sandboxing & Secure Execution Environments
-   Information Flow Control (IFC)
-   Human Oversight & Control
-   Value Alignment
